{'google crawling (following', 'email databases); yell.com', 'data; auto portals', 'during my job', 'yell.com crawling to', "client's sites; jobs", 'getting email databases);', 'to get data', 'information); google crawling', 'CTO at Periodix.net', 'companies contact data;', 'I have a', "flows for client's", 'news crawling to', 'contact data; auto', 'to get companies', 'get data for', "client's job site;", 'sites; jobs crawling', 'get news flows', "for client's job", 'job as a', 'Some of my', 'get companies contact', 'portals crawling and', '(following search results,', 'livingsocials crawling (company', 'a CTO at', 'crawling (company information);', '(company information); google', "client's site; making", "for client's sites;", 'image processing to', 'my job as', 'processing to get', 'search results, getting', 'I can do', "for client's site;", 'news flows for', 'crawling (following search', 'auto portals crawling', 'and livingsocials crawling', 'job site; etc.', "data for client's", 'and image processing', 'jobs crawling to', 'crawling to get', 'as a CTO', 'crawling and image', 'to get news', 'results, getting email', 'databases); yell.com crawling', 'groupon and livingsocials'}
{'I have a', 'have a relevant'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'contact data; auto', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'Thank you, Rinat', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'pages and terabytes', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', "Hello, I'm Rinat", 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'and optimize the', 'to get news', 'databases); yell.com crawling'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'CTO at Periodix.net', 'and user actions', 'the load, optimize', 'distribute and optimize', 'browsers and user', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'a CTO at', 'avoid bans, how', 'user actions and', 'have a relevant', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'as a CTO', 'and optimize the'}
{'this job in', 'Periodix.net startup (2', 'at Periodix.net startup', 'Rinat from Ukraine.', 'know how to', 'I know how', "I'm Rinat from", 'startup (2 years).', 'Ukraine. My skype', 'from Ukraine. My'}
{'Periodix.net startup (2', 'at Periodix.net startup', 'a CTO at', 'Rinat from Ukraine.', 'as a CTO', "I'm Rinat from", 'startup (2 years).', 'Ukraine. My skype', 'from Ukraine. My', 'CTO at Periodix.net'}
{'site; making copies', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'pages and terabytes', 'to get news'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'how to crawl', 'of scanned pages', 'threads in a', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'good example is', 'are: groupon and', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'Another good example', 'crawling (following search', 'processed data. Some', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'example is crawling', 'get data for', "client's job site;", 'of processed data.', 'is crawling Ukrainian', 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'how to distribute', 'scrappers are: groupon', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'years). Another good', "data for client's", 'other previous scrappers', "for client's job", 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', '(2 years). Another', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'pages and terabytes', 'to get news', 'databases); yell.com crawling'}
{'and terabytes of', 'to get data', 'of scanned pages', 'threads in a', 'I have a', 'a cloud, millions', 'get data for', 'millions of scanned', 'of processed data.', 'sites during my', 'in a cloud,', 'cloud, millions of', 'active threads in', 'a CTO at', '200+ active threads', 'crawling Ukrainian automotive', 'have a relevant', 'automotive sites with', 'scanned pages and', 'with 200+ active', 'sites with 200+', 'pages and terabytes', 'Thank you, Rinat', 'Ukrainian automotive sites', 'terabytes of processed'}
{'simulate browsers and', 'to distribute and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'and user actions', 'ajax-driven sites, how', 'the load, optimize', 'distribute and optimize', 'browsers and user', 'how to distribute', 'load, optimize DB', 'optimize the load,', 'to crawl js-driven', 'optimize DB queries', 'get rid of', 'how to simulate', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'avoid bans, how', 'user actions and', 'etc. I have', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'sites, how to', 'I know how', 'and optimize the'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'and user actions', 'the load, optimize', 'distribute and optimize', 'Rinat from Ukraine.', 'browsers and user', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'Ukraine. My skype', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'avoid bans, how', "I'm Rinat from", 'user actions and', 'have a relevant', 'from Ukraine. My', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'and optimize the'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'how to crawl', 'of scanned pages', 'threads in a', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'good example is', 'are: groupon and', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Ukraine. My skype', 'Some of my', 'of the duplicates,', 'and optimize the', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'Another good example', 'crawling (following search', 'processed data. Some', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'the load, optimize', 'to get companies', 'example is crawling', 'get data for', "client's job site;", 'of processed data.', 'is crawling Ukrainian', 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'how to distribute', 'scrappers are: groupon', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'years). Another good', "data for client's", 'other previous scrappers', "for client's job", 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', '(2 years). Another', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'duplicates, etc. Thank', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'pages and terabytes', 'to get news', 'databases); yell.com crawling'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'contact data; auto', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'Thank you, Rinat', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'pages and terabytes', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', "Hello, I'm Rinat", 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'and optimize the', 'to get news', 'databases); yell.com crawling'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'contact data; auto', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'Thank you, Rinat', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'pages and terabytes', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', "Hello, I'm Rinat", 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'and optimize the', 'to get news', 'databases); yell.com crawling'}
{'simulate browsers and', 'etc. Thank you,', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'and user actions', 'the load, optimize', 'distribute and optimize', 'Rinat from Ukraine.', 'browsers and user', 'to crawl js-driven', 'load, optimize DB', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'Ukraine. My skype', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'avoid bans, how', "I'm Rinat from", 'user actions and', 'duplicates, etc. Thank', 'from Ukraine. My', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'and optimize the'}
{'site; making copies', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'pages and terabytes', 'to get news'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'contact data; auto', 'news crawling to', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Some of my', 'of the duplicates,', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'Thank you, Rinat', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'pages and terabytes', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'duplicates, etc. Thank', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'and optimize the', 'to get news', 'databases); yell.com crawling'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'I have a', 'and user actions', 'the load, optimize', 'distribute and optimize', 'Rinat from Ukraine.', 'browsers and user', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'Ukraine. My skype', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'avoid bans, how', "I'm Rinat from", 'user actions and', 'have a relevant', 'from Ukraine. My', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'and optimize the'}
{'I have an'}
{'site; making copies', 'and terabytes of', 'of scanned pages', 'how to crawl', 'threads in a', 'contact data; auto', 'news crawling to', 'Rinat from Ukraine.', 'browsers and user', 'millions of scanned', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'crawl js-driven and', 'and image processing', 'actions and avoid', 'previous scrappers are:', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'and user actions', 'a cloud, millions', "flows for client's", 'sites; jobs crawling', "Hello, I'm Rinat", 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', 'avoid bans, how', '200+ active threads', 'queries and get', 'scanned pages and', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'how to simulate', 'in a cloud,', 'get companies contact', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'pages and terabytes', 'to get news', 'databases); yell.com crawling'}
{'site; making copies', 'and terabytes of', 'of scanned pages', 'how to crawl', 'threads in a', 'contact data; auto', 'news crawling to', 'Rinat from Ukraine.', 'browsers and user', 'millions of scanned', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'Thank you, Rinat', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'crawl js-driven and', 'and image processing', 'actions and avoid', 'previous scrappers are:', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'and user actions', 'a cloud, millions', "flows for client's", 'sites; jobs crawling', "Hello, I'm Rinat", 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', 'avoid bans, how', '200+ active threads', 'queries and get', 'scanned pages and', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'how to simulate', 'in a cloud,', 'get companies contact', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'pages and terabytes', 'to get news', 'databases); yell.com crawling'}
{'site; making copies', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'contact data; auto', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'Thank you, Rinat', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', "Hello, I'm Rinat", 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'pages and terabytes', 'to get news', 'databases); yell.com crawling'}
{'site; making copies', 'and terabytes of', 'of scanned pages', 'how to crawl', 'threads in a', 'contact data; auto', 'news crawling to', 'Rinat from Ukraine.', 'browsers and user', 'millions of scanned', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'Thank you, Rinat', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'crawl js-driven and', 'and image processing', 'actions and avoid', 'previous scrappers are:', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'and user actions', 'a cloud, millions', "flows for client's", 'sites; jobs crawling', "Hello, I'm Rinat", 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', 'avoid bans, how', '200+ active threads', 'queries and get', 'scanned pages and', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'how to simulate', 'in a cloud,', 'get companies contact', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'pages and terabytes', 'to get news', 'databases); yell.com crawling'}
{'site; making copies', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'promios I can', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'pages and terabytes', 'to get news'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'CTO at Periodix.net', 'and user actions', 'the load, optimize', 'distribute and optimize', 'browsers and user', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'a CTO at', 'avoid bans, how', 'user actions and', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'as a CTO', 'and optimize the'}
{'Periodix.net startup (2', 'at Periodix.net startup', 'my job as', 'a CTO at', 'Rinat from Ukraine.', 'from Ukraine. My', 'as a CTO', "I'm Rinat from", 'startup (2 years).', 'how to simulate', 'Ukraine. My skype', 'job as a', 'CTO at Periodix.net'}
{'etc. Thank you,', 'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'I have a', 'and user actions', 'the load, optimize', 'distribute and optimize', 'browsers and user', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'a CTO at', 'avoid bans, how', 'user actions and', 'duplicates, etc. Thank', 'have a relevant', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'as a CTO', 'and optimize the', 'Thank you, Rinat'}
{'a CTO at', 'as a CTO'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'how to crawl', 'of scanned pages', 'threads in a', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'good example is', 'are: groupon and', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Ukraine. My skype', 'Some of my', 'of the duplicates,', 'and optimize the', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'Another good example', 'crawling (following search', 'processed data. Some', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'the load, optimize', 'to get companies', 'example is crawling', 'get data for', "client's job site;", 'of processed data.', 'is crawling Ukrainian', 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'how to distribute', 'scrappers are: groupon', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'job in 24', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'years). Another good', "data for client's", 'other previous scrappers', "for client's job", 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', '(2 years). Another', 'in a cloud,', 'get companies contact', 'how to simulate', 'this job in', 'site; etc. I', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'duplicates, etc. Thank', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'pages and terabytes', 'to get news', 'databases); yell.com crawling'}
{'know how to'}
{'Ukraine. My skype', "I'm Rinat from", 'from Ukraine. My', 'Rinat from Ukraine.'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'contact data; auto', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'Thank you, Rinat', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'pages and terabytes', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', "Hello, I'm Rinat", 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'and optimize the', 'to get news', 'databases); yell.com crawling'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'and user actions', 'the load, optimize', 'distribute and optimize', 'browsers and user', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'avoid bans, how', 'user actions and', 'have a relevant', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'and optimize the'}
{'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'a CTO at', '(company information); google', "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'actions and avoid', 'crawling to get', 'crawling and image', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'how to simulate', 'in a cloud,', 'get companies contact', 'crawling Ukrainian automotive', 'user actions and', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'pages and terabytes', 'to get news'}
{"I'm Rinat from"}
{'site; making copies', 'and terabytes of', 'of scanned pages', 'how to crawl', 'threads in a', 'contact data; auto', 'news crawling to', 'browsers and user', 'millions of scanned', 'including data; news', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'sites during my', 'and avoid bans,', 'job as a', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'crawl js-driven and', 'and image processing', 'actions and avoid', 'previous scrappers are:', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'and user actions', 'a cloud, millions', "flows for client's", 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', 'avoid bans, how', '200+ active threads', 'queries and get', 'scanned pages and', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'how to simulate', 'in a cloud,', 'get companies contact', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'pages and terabytes', 'to get news', 'databases); yell.com crawling'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'how to crawl', 'of scanned pages', 'threads in a', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'good example is', 'are: groupon and', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Ukraine. My skype', 'Some of my', 'of the duplicates,', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'automotive sites with', 'Another good example', 'crawling (following search', 'processed data. Some', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'pages and terabytes', 'rid of the', 'the load, optimize', 'an experience crawling', 'to get companies', 'example is crawling', 'get data for', "client's job site;", 'of processed data.', 'is crawling Ukrainian', 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'experience crawling sites', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', "Hello, I'm Rinat", 'how to distribute', 'scrappers are: groupon', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'years). Another good', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'have an experience', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', '(2 years). Another', 'in a cloud,', 'get companies contact', 'how to simulate', 'I have an', 'site; etc. I', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'duplicates, etc. Thank', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'and optimize the', 'to get news', 'databases); yell.com crawling'}
{'Ukraine. My skype', "I'm Rinat from", 'from Ukraine. My', 'Rinat from Ukraine.'}
{'site; making copies', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'contact data; auto', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'I can do', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'pages and terabytes', 'to get news', 'databases); yell.com crawling'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'and user actions', 'the load, optimize', 'distribute and optimize', 'browsers and user', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'avoid bans, how', 'user actions and', 'have a relevant', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'and optimize the'}
{'to distribute and', 'know how to', 'My skype id', 'id is promios', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'I have a', 'ajax-driven sites, how', 'the load, optimize', 'distribute and optimize', 'Rinat from Ukraine.', 'how to distribute', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'get rid of', 'job as a', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'avoid bans, how', "I'm Rinat from", 'user actions and', 'my job as', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'sites, how to', 'I know how', 'as a CTO', 'skype id is', 'and optimize the', 'Thank you, Rinat'}
{'Thank you, Rinat'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'how to crawl', 'of scanned pages', 'threads in a', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'good example is', 'are: groupon and', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Some of my', 'of the duplicates,', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'Another good example', 'crawling (following search', 'processed data. Some', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'pages and terabytes', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'example is crawling', 'get data for', "client's job site;", 'of processed data.', 'is crawling Ukrainian', 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'how to distribute', 'scrappers are: groupon', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'years). Another good', "data for client's", 'other previous scrappers', "for client's job", 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', '(2 years). Another', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'and optimize the', 'to get news', 'databases); yell.com crawling'}
{'simulate browsers and', 'to distribute and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'and user actions', 'ajax-driven sites, how', 'the load, optimize', 'distribute and optimize', 'Rinat from Ukraine.', 'browsers and user', 'to crawl js-driven', 'how to distribute', 'optimize the load,', 'load, optimize DB', 'optimize DB queries', 'get rid of', 'how to simulate', 'Ukraine. My skype', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'avoid bans, how', "I'm Rinat from", 'user actions and', 'from Ukraine. My', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'sites, how to', 'I know how', 'and optimize the'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'how to crawl', 'of scanned pages', 'threads in a', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'good example is', 'are: groupon and', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Ukraine. My skype', 'Some of my', 'of the duplicates,', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'Another good example', 'crawling (following search', 'processed data. Some', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'pages and terabytes', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'example is crawling', 'get data for', "client's job site;", 'of processed data.', 'is crawling Ukrainian', 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'scrapping data from', 'sites; jobs crawling', 'how to distribute', 'scrappers are: groupon', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', "data for client's", 'other previous scrappers', "for client's job", 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'duplicates, etc. Thank', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'and optimize the', 'to get news', 'databases); yell.com crawling'}
{'site; making copies', 'google crawling (following', 'copies of some', 'and terabytes of', 'yell.com crawling to', "client's sites; jobs", 'making copies of', 'getting email databases);', 'to get data', 'information); google crawling', 'pages and terabytes', 'of scanned pages', 'threads in a', 'companies contact data;', 'I have a', 'a cloud, millions', "flows for client's", 'news crawling to', 'to get companies', 'get data for', "client's job site;", 'sites; jobs crawling', 'Rinat from Ukraine.', 'millions of scanned', 'including data; news', 'in a cloud,', 'Ukraine. My skype', 'get news flows', 'of my other', 'Some of my', 'cloud, millions of', "for client's job", 'get companies contact', 'active threads in', 'portals crawling and', '(following search results,', 'this job in', 'site; etc. I', 'livingsocials crawling (company', 'data; news crawling', 'sites, including data;', 'crawling (company information);', '(company information); google', "client's site; making", '200+ active threads', 'crawling Ukrainian automotive', "I'm Rinat from", 'some sites, including', "for client's sites;", 'image processing to', 'my other previous', 'processing to get', 'have a relevant', 'automotive sites with', 'from Ukraine. My', 'search results, getting', 'scanned pages and', "for client's site;", 'crawling (following search', 'news flows for', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'auto portals crawling', 'sites with 200+', "data for client's", 'and image processing', 'previous scrappers are:', 'jobs crawling to', 'crawling to get', 'other previous scrappers', 'crawling and image', 'to get news', 'results, getting email', 'of some sites,', 'Ukrainian automotive sites', 'terabytes of processed', 'groupon and livingsocials'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'how to crawl', 'of scanned pages', 'threads in a', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'good example is', 'are: groupon and', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Ukraine. My skype', 'Some of my', 'of the duplicates,', 'and optimize the', 'Periodix.net startup (2', 'livingsocials crawling (company', 'on various business', 'image processing to', 'have a relevant', 'Another good example', 'automotive sites with', 'crawling (following search', 'processed data. Some', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'an experience crawling', 'to get companies', 'example is crawling', 'get data for', "client's job site;", 'of processed data.', 'is crawling Ukrainian', 'sites during my', 'various business directions', 'job as a', 'and avoid bans,', 'business directions from', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'experience crawling sites', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', "Hello, I'm Rinat", 'how to distribute', 'scrappers are: groupon', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'years). Another good', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'have an experience', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', '(2 years). Another', 'in a cloud,', 'get companies contact', 'how to simulate', 'I have an', 'this job in', 'site; etc. I', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'duplicates, etc. Thank', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'directions from yell.com,', 'jobs crawling to', 'as a CTO', 'based on various', 'pages and terabytes', 'to get news', 'startup (2 years).', 'databases); yell.com crawling'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'CTO at Periodix.net', 'I have a', 'and user actions', 'the load, optimize', 'distribute and optimize', 'Rinat from Ukraine.', 'browsers and user', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'Ukraine. My skype', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'a CTO at', 'avoid bans, how', "I'm Rinat from", 'user actions and', 'have a relevant', 'from Ukraine. My', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'as a CTO', 'and optimize the'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'I have a', 'and user actions', 'distribute and optimize', 'Rinat from Ukraine.', 'browsers and user', 'to crawl js-driven', 'how to simulate', 'Ukraine. My skype', 'and avoid bans,', 'bans, how to', 'at Periodix.net startup', 'avoid bans, how', "I'm Rinat from", 'user actions and', 'have a relevant', 'from Ukraine. My', 'crawl js-driven and', 'actions and avoid', 'I know how', 'and optimize the'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'how to crawl', 'of scanned pages', 'threads in a', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'are: groupon and', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Some of my', 'of the duplicates,', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'crawling (following search', 'processed data. Some', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'pages and terabytes', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'of processed data.', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'how to distribute', 'scrappers are: groupon', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', "data for client's", 'other previous scrappers', "for client's job", 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'duplicates, etc. Thank', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'and optimize the', 'to get news', 'databases); yell.com crawling'}
{'I have a', "I'm Rinat from", 'from Ukraine. My', 'Rinat from Ukraine.'}
{'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'a CTO at', '(company information); google', "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'actions and avoid', 'crawling to get', 'crawling and image', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'how to simulate', 'in a cloud,', 'get companies contact', 'promios I can', 'crawling Ukrainian automotive', 'user actions and', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'pages and terabytes', 'to get news'}
{'site; making copies', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'pages and terabytes', 'to get news'}
{'Ukraine. My skype', "I'm Rinat from", 'from Ukraine. My', 'Rinat from Ukraine.'}
{'Periodix.net startup (2', 'at Periodix.net startup', 'Rinat from Ukraine.', 'know how to', 'I know how', "I'm Rinat from", 'startup (2 years).', 'Ukraine. My skype', 'from Ukraine. My'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'and user actions', 'the load, optimize', 'distribute and optimize', "Hello, I'm Rinat", 'Rinat from Ukraine.', 'browsers and user', 'to crawl js-driven', 'load, optimize DB', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'Ukraine. My skype', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'avoid bans, how', "I'm Rinat from", 'user actions and', 'from Ukraine. My', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'and optimize the', 'Thank you, Rinat'}
{'site; making copies', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'pages and terabytes', 'to get news'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'CTO at Periodix.net', 'I have a', 'and user actions', 'the load, optimize', 'distribute and optimize', 'browsers and user', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'a CTO at', 'avoid bans, how', 'user actions and', 'have a relevant', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'as a CTO', 'and optimize the'}
{'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'news crawling to', 'millions of scanned', 'browsers and user', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'a CTO at', '(company information); google', "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'actions and avoid', 'crawling to get', 'crawling and image', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'how to simulate', 'in a cloud,', 'get companies contact', 'site; etc. I', 'crawling Ukrainian automotive', 'user actions and', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'pages and terabytes', 'to get news'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'how to crawl', 'of scanned pages', 'threads in a', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'good example is', 'are: groupon and', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Ukraine. My skype', 'Some of my', 'of the duplicates,', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'Another good example', 'crawling (following search', 'processed data. Some', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'pages and terabytes', 'rid of the', 'the load, optimize', 'to get companies', 'example is crawling', 'get data for', "client's job site;", 'of processed data.', 'is crawling Ukrainian', 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'how to distribute', 'scrappers are: groupon', 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', "data for client's", 'other previous scrappers', "for client's job", 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'duplicates, etc. Thank', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'and optimize the', 'to get news', 'databases); yell.com crawling'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'from yell.com, google.com,', 'of scanned pages', 'how to crawl', 'threads in a', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'good example is', 'are: groupon and', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Ukraine. My skype', 'Some of my', 'of the duplicates,', 'Periodix.net startup (2', 'livingsocials crawling (company', 'on various business', 'image processing to', 'have a relevant', 'Another good example', 'automotive sites with', 'crawling (following search', 'processed data. Some', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'pages and terabytes', 'rid of the', 'I have a', 'the load, optimize', 'company data based', 'an experience crawling', 'example is crawling', 'to get companies', "client's job site;", 'get data for', 'of processed data.', 'is crawling Ukrainian', 'sites during my', 'various business directions', 'job as a', 'and avoid bans,', 'business directions from', 'active threads in', 'portals crawling and', 'data; news crawling', 'google.com, craigslist.com, backpage.com', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'craigslist.com, backpage.com etc.', 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'experience crawling sites', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'yell.com, google.com, craigslist.com,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'crawling emails and/or', 'sites; jobs crawling', "Hello, I'm Rinat", 'how to distribute', 'scrappers are: groupon', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'data based on', 'years). Another good', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'have an experience', 'CTO at Periodix.net', 'and/or company data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', '(2 years). Another', 'emails and/or company', 'in a cloud,', 'get companies contact', 'how to simulate', 'I have an', 'site; etc. I', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'directions from yell.com,', 'jobs crawling to', 'as a CTO', 'based on various', 'and optimize the', 'to get news', 'startup (2 years).', 'databases); yell.com crawling'}
{'google crawling (following', 'yell.com crawling to', "client's sites; jobs", 'getting email databases);', 'to get data', 'companies contact data;', 'I have a', "flows for client's", 'news crawling to', 'get data for', 'to get companies', "client's job site;", 'sites; jobs crawling', 'get news flows', "for client's job", 'get companies contact', 'portals crawling and', '(following search results,', "for client's sites;", 'image processing to', 'processing to get', 'search results, getting', "for client's site;", 'news flows for', 'crawling (following search', 'auto portals crawling', 'job site; etc.', "data for client's", 'and image processing', 'jobs crawling to', 'crawling to get', 'crawling and image', 'to get news', 'results, getting email'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'I have a', 'and user actions', 'distribute and optimize', 'Rinat from Ukraine.', 'browsers and user', 'to crawl js-driven', 'how to simulate', 'Ukraine. My skype', 'and avoid bans,', 'bans, how to', 'avoid bans, how', "I'm Rinat from", 'user actions and', 'have a relevant', 'from Ukraine. My', 'crawl js-driven and', 'actions and avoid', 'I know how', 'and optimize the'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'of scanned pages', 'how to crawl', 'threads in a', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'good example is', 'are: groupon and', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Ukraine. My skype', 'Some of my', 'of the duplicates,', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'Another good example', 'crawling (following search', 'processed data. Some', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'pages and terabytes', 'rid of the', 'the load, optimize', 'to get companies', 'example is crawling', 'get data for', "client's job site;", 'of processed data.', 'is crawling Ukrainian', 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'how to distribute', 'scrappers are: groupon', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'years). Another good', "data for client's", 'other previous scrappers', "for client's job", 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', '(2 years). Another', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'duplicates, etc. Thank', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'and optimize the', 'to get news', 'databases); yell.com crawling'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'CTO at Periodix.net', 'I have a', 'and user actions', 'the load, optimize', 'scrapping data from', 'distribute and optimize', 'Rinat from Ukraine.', 'browsers and user', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'Ukraine. My skype', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'a CTO at', 'avoid bans, how', "I'm Rinat from", 'user actions and', 'have a relevant', 'from Ukraine. My', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'as a CTO', 'and optimize the'}
{'site; making copies', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'news crawling to', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', '(company information); google', "client's site; making", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'pages and terabytes', 'to get news'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'I have a', 'and user actions', 'distribute and optimize', 'Rinat from Ukraine.', 'browsers and user', 'to crawl js-driven', 'how to simulate', 'Ukraine. My skype', 'and avoid bans,', 'bans, how to', 'avoid bans, how', "I'm Rinat from", 'user actions and', 'have a relevant', 'from Ukraine. My', 'crawl js-driven and', 'actions and avoid', 'I know how', 'and optimize the'}
{'I have a', 'this job in'}
{'site; making copies', 'and terabytes of', 'of scanned pages', 'how to crawl', 'threads in a', 'news crawling to', 'Rinat from Ukraine.', 'browsers and user', 'millions of scanned', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'Thank you, Rinat', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'crawl js-driven and', 'and image processing', 'actions and avoid', 'previous scrappers are:', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'and user actions', 'a cloud, millions', "flows for client's", 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', 'avoid bans, how', '200+ active threads', 'queries and get', 'scanned pages and', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'how to simulate', 'get companies contact', 'in a cloud,', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'pages and terabytes', 'to get news'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'I have a', 'and user actions', 'the load, optimize', 'distribute and optimize', 'Rinat from Ukraine.', 'browsers and user', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'Ukraine. My skype', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'at Periodix.net startup', 'avoid bans, how', "I'm Rinat from", 'user actions and', 'have a relevant', 'from Ukraine. My', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'and optimize the'}
{"I'm Rinat from", 'Some of my'}
{'simulate browsers and', 'etc. Thank you,', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'and user actions', 'the load, optimize', 'distribute and optimize', 'browsers and user', 'to crawl js-driven', 'load, optimize DB', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'promios I can', 'this job in', 'avoid bans, how', 'user actions and', 'duplicates, etc. Thank', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'and optimize the'}
{'Periodix.net startup (2', 'at Periodix.net startup', 'a CTO at', 'Rinat from Ukraine.', 'know how to', 'I know how', 'as a CTO', "I'm Rinat from", 'startup (2 years).', 'Ukraine. My skype', 'from Ukraine. My', 'CTO at Periodix.net'}
{'know how to'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'contact data; auto', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'pages and terabytes', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'duplicates, etc. Thank', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'and optimize the', 'to get news', 'databases); yell.com crawling'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'how to crawl', 'of scanned pages', 'threads in a', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'good example is', 'are: groupon and', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Ukraine. My skype', 'Some of my', 'of the duplicates,', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'automotive sites with', 'Another good example', 'crawling (following search', 'processed data. Some', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'pages and terabytes', 'rid of the', 'I have a', 'the load, optimize', 'an experience crawling', 'to get companies', 'example is crawling', 'get data for', "client's job site;", 'of processed data.', 'is crawling Ukrainian', 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'experience crawling sites', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'how to distribute', 'scrappers are: groupon', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'years). Another good', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'have an experience', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', '(2 years). Another', 'in a cloud,', 'get companies contact', 'how to simulate', 'I have an', 'site; etc. I', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'duplicates, etc. Thank', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'and optimize the', 'to get news', 'databases); yell.com crawling'}
{'I have a', "I'm Rinat from"}
{'Thank you, Rinat'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'CTO at Periodix.net', 'I have a', 'and user actions', 'the load, optimize', 'distribute and optimize', 'Rinat from Ukraine.', 'browsers and user', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'Ukraine. My skype', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'a CTO at', 'avoid bans, how', "I'm Rinat from", 'user actions and', 'have a relevant', 'from Ukraine. My', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'as a CTO', 'and optimize the'}
{'site; making copies', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'pages and terabytes', 'to get news'}
{'Thank you, Rinat', 'this job in', 'do this job', 'I can do', 'can do this'}
{'site; making copies', 'and terabytes of', 'of scanned pages', 'how to crawl', 'threads in a', 'news crawling to', 'Rinat from Ukraine.', 'browsers and user', 'millions of scanned', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'Thank you, Rinat', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'crawl js-driven and', 'and image processing', 'actions and avoid', 'previous scrappers are:', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'and user actions', 'a cloud, millions', "flows for client's", 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', 'avoid bans, how', '200+ active threads', 'queries and get', 'scanned pages and', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'how to simulate', 'get companies contact', 'in a cloud,', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'pages and terabytes', 'to get news'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'CTO at Periodix.net', 'and user actions', 'the load, optimize', 'distribute and optimize', 'browsers and user', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'a CTO at', 'avoid bans, how', 'user actions and', 'have a relevant', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'as a CTO', 'and optimize the'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'I have a', 'and user actions', 'the load, optimize', 'distribute and optimize', 'Rinat from Ukraine.', 'browsers and user', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'Ukraine. My skype', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'at Periodix.net startup', 'avoid bans, how', "I'm Rinat from", 'user actions and', 'have a relevant', 'from Ukraine. My', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'and optimize the'}
{'Thank you, Rinat'}
{'site; making copies', 'and terabytes of', 'of scanned pages', 'how to crawl', 'threads in a', 'contact data; auto', 'news crawling to', 'Rinat from Ukraine.', 'browsers and user', 'millions of scanned', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'sites during my', 'and avoid bans,', 'job as a', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'crawl js-driven and', 'and image processing', 'actions and avoid', 'previous scrappers are:', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'and user actions', 'a cloud, millions', "flows for client's", 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', 'avoid bans, how', '200+ active threads', 'queries and get', 'scanned pages and', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'how to simulate', 'in a cloud,', 'get companies contact', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'pages and terabytes', 'to get news', 'databases); yell.com crawling'}
{'site; making copies', 'and terabytes of', 'of scanned pages', 'how to crawl', 'threads in a', 'news crawling to', 'Rinat from Ukraine.', 'browsers and user', 'millions of scanned', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'crawl js-driven and', 'and image processing', 'actions and avoid', 'previous scrappers are:', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'and user actions', 'a cloud, millions', "flows for client's", 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', 'avoid bans, how', '200+ active threads', 'queries and get', 'scanned pages and', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'how to simulate', 'in a cloud,', 'get companies contact', 'promios I can', 'this job in', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'pages and terabytes', 'to get news'}
{'I have a', 'Periodix.net startup (2', 'at Periodix.net startup', 'a CTO at', 'Rinat from Ukraine.', 'from Ukraine. My', 'have a relevant', 'as a CTO', "I'm Rinat from", 'startup (2 years).', 'my job as', 'Ukraine. My skype', 'job as a', 'CTO at Periodix.net'}
{'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'news crawling to', 'millions of scanned', 'browsers and user', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'a CTO at', '(company information); google', "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'actions and avoid', 'crawling to get', 'crawling and image', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'how to simulate', 'in a cloud,', 'get companies contact', 'crawling Ukrainian automotive', 'user actions and', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'pages and terabytes', 'to get news'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'and user actions', 'the load, optimize', 'distribute and optimize', 'browsers and user', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'get rid of', 'how to simulate', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'avoid bans, how', 'user actions and', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'and optimize the'}
{'simulate browsers and', 'to distribute and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'CTO at Periodix.net', 'and user actions', 'ajax-driven sites, how', 'the load, optimize', 'distribute and optimize', 'Rinat from Ukraine.', 'browsers and user', 'how to distribute', 'load, optimize DB', 'optimize the load,', 'to crawl js-driven', 'optimize DB queries', 'get rid of', 'how to simulate', 'Ukraine. My skype', 'and avoid bans,', 'job as a', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'Periodix.net startup (2', 'at Periodix.net startup', 'a CTO at', 'avoid bans, how', "I'm Rinat from", 'user actions and', 'my job as', 'from Ukraine. My', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'sites, how to', 'I know how', 'as a CTO', 'startup (2 years).', 'and optimize the'}
{'Periodix.net startup (2', 'at Periodix.net startup', 'Rinat from Ukraine.', 'know how to', 'I know how', "I'm Rinat from", 'startup (2 years).', 'Ukraine. My skype', 'from Ukraine. My'}
{'I have a', 'at Periodix.net startup', 'a CTO at', "Hello, I'm Rinat", 'Rinat from Ukraine.', 'as a CTO', "I'm Rinat from", 'CTO at Periodix.net', 'Ukraine. My skype', 'from Ukraine. My', 'have a relevant'}
{'and terabytes of', 'of scanned pages', 'how to crawl', 'threads in a', 'news crawling to', 'browsers and user', 'millions of scanned', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'a CTO at', '(company information); google', "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'crawl js-driven and', 'and image processing', 'actions and avoid', 'crawling to get', 'crawling and image', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'and user actions', 'a cloud, millions', "flows for client's", 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', 'avoid bans, how', '200+ active threads', 'queries and get', 'scanned pages and', 'sites with 200+', "data for client's", "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'how to simulate', 'in a cloud,', 'get companies contact', 'crawling Ukrainian automotive', 'user actions and', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'pages and terabytes', 'to get news'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'how to crawl', 'of scanned pages', 'threads in a', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'good example is', 'are: groupon and', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Ukraine. My skype', 'Some of my', 'of the duplicates,', 'and optimize the', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'automotive sites with', 'Another good example', 'crawling (following search', 'processed data. Some', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'the load, optimize', 'an experience crawling', 'to get companies', 'example is crawling', 'get data for', "client's job site;", 'of processed data.', 'is crawling Ukrainian', 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'experience crawling sites', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', "Hello, I'm Rinat", 'how to distribute', 'scrappers are: groupon', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'have an experience', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'I have an', 'this job in', 'site; etc. I', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'duplicates, etc. Thank', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'pages and terabytes', 'to get news', 'databases); yell.com crawling'}
{'simulate browsers and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'CTO at Periodix.net', 'and user actions', 'the load, optimize', 'distribute and optimize', 'browsers and user', 'load, optimize DB', 'to crawl js-driven', 'optimize the load,', 'optimize DB queries', 'sites during my', 'get rid of', 'how to simulate', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'at Periodix.net startup', 'a CTO at', 'avoid bans, how', 'user actions and', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'I know how', 'and optimize the'}
{'I have a', "Hello, I'm Rinat", 'Rinat from Ukraine.', "I'm Rinat from", 'Ukraine. My skype', 'from Ukraine. My', 'have a relevant'}
{'site; making copies', 'and terabytes of', 'of scanned pages', 'how to crawl', 'threads in a', 'news crawling to', 'Rinat from Ukraine.', 'browsers and user', 'millions of scanned', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'crawl js-driven and', 'and image processing', 'actions and avoid', 'previous scrappers are:', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'and user actions', 'a cloud, millions', "flows for client's", 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', 'avoid bans, how', '200+ active threads', 'queries and get', 'scanned pages and', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'how to simulate', 'in a cloud,', 'get companies contact', 'site; etc. I', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'pages and terabytes', 'to get news'}
{'at Periodix.net startup', 'a CTO at', 'Rinat from Ukraine.', 'My skype id', "I'm Rinat from", 'CTO at Periodix.net'}
{'site; making copies', 'and terabytes of', 'of scanned pages', 'how to crawl', 'threads in a', 'news crawling to', 'Rinat from Ukraine.', 'browsers and user', 'millions of scanned', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'Thank you, Rinat', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'crawl js-driven and', 'and image processing', 'actions and avoid', 'previous scrappers are:', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'and user actions', 'a cloud, millions', "flows for client's", 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'of my other', 'cloud, millions of', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', 'avoid bans, how', '200+ active threads', 'queries and get', 'scanned pages and', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'how to simulate', 'get companies contact', 'in a cloud,', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'pages and terabytes', 'to get news'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'how to crawl', 'of scanned pages', 'threads in a', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'good example is', 'are: groupon and', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Ukraine. My skype', 'Some of my', 'of the duplicates,', 'and optimize the', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'Another good example', 'crawling (following search', 'processed data. Some', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'the load, optimize', 'to get companies', 'example is crawling', 'get data for', "client's job site;", 'of processed data.', 'is crawling Ukrainian', 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'how to distribute', 'scrappers are: groupon', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', "data for client's", 'other previous scrappers', "for client's job", 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'this job in', 'site; etc. I', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'duplicates, etc. Thank', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'pages and terabytes', 'to get news', 'databases); yell.com crawling'}
{'Periodix.net startup (2', 'at Periodix.net startup', 'a CTO at', 'Rinat from Ukraine.', 'as a CTO', "I'm Rinat from", 'startup (2 years).', 'Ukraine. My skype', 'from Ukraine. My', 'CTO at Periodix.net'}
{'site; making copies', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'pages and terabytes', 'to get news'}
{'Thank you, Rinat', "I'm Rinat from", 'Rinat from Ukraine.'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'how to crawl', 'of scanned pages', 'threads in a', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'good example is', 'are: groupon and', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Some of my', 'of the duplicates,', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'Another good example', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'pages and terabytes', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'example is crawling', 'get data for', "client's job site;", 'of processed data.', 'is crawling Ukrainian', 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'how to distribute', 'scrappers are: groupon', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'and optimize the', 'to get news', 'databases); yell.com crawling'}
{'site; making copies', 'and terabytes of', 'how to crawl', 'of scanned pages', 'threads in a', 'news crawling to', 'Rinat from Ukraine.', 'millions of scanned', 'browsers and user', 'including data; news', 'Ukraine. My skype', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'livingsocials crawling (company', 'image processing to', 'have a relevant', 'automotive sites with', 'crawling (following search', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', '(company information); google', "client's site; making", "I'm Rinat from", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'making copies of', 'getting email databases);', 'to get data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'from Ukraine. My', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'pages and terabytes', 'to get news'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'how to crawl', 'of scanned pages', 'threads in a', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Some of my', 'of the duplicates,', 'Periodix.net startup (2', 'image processing to', 'crawling (following search', 'processed data. Some', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'pages and terabytes', 'rid of the', 'I have a', 'the load, optimize', 'to get companies', 'get data for', "client's job site;", 'of processed data.', 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', "client's site; making", "for client's sites;", 'processing to get', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'how to distribute', 'load, optimize DB', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', "data for client's", 'other previous scrappers', "for client's job", 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', 'in a cloud,', 'get companies contact', 'how to simulate', 'site; etc. I', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'DB queries and', 'jobs crawling to', 'as a CTO', 'and optimize the', 'to get news', 'databases); yell.com crawling'}
{'site; making copies', 'etc. I know', 'and terabytes of', 'to distribute and', 'from yell.com, google.com,', 'of scanned pages', 'how to crawl', 'threads in a', 'a relevant job', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'good example is', 'are: groupon and', 'millions of scanned', 'browsers and user', 'including data; news', 'job experience: crawling', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'Periodix.net startup (2', 'livingsocials crawling (company', 'on various business', 'image processing to', 'have a relevant', 'Another good example', 'automotive sites with', 'I can do', 'crawling (following search', 'processed data. Some', 'I know how', 'Thank you, Rinat', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'I have a', 'the load, optimize', 'company data based', 'an experience crawling', 'example is crawling', 'to get companies', "client's job site;", 'get data for', 'of processed data.', 'is crawling Ukrainian', 'sites during my', 'various business directions', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'google.com, craigslist.com, backpage.com', 'a CTO at', '(company information); google', "client's site; making", 'experience: crawling emails', "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and get rid', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'etc. Thank you,', 'google crawling (following', 'would I do', 'experience crawling sites', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'yell.com, google.com, craigslist.com,', 'companies contact data;', 'relevant job experience:', 'a cloud, millions', "flows for client's", 'and user actions', 'crawling emails and/or', 'sites; jobs crawling', 'how to distribute', 'scrappers are: groupon', 'load, optimize DB', 'optimize the load,', 'How would I', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', 'queries and get', 'data based on', 'years). Another good', 'sites with 200+', "data for client's", 'other previous scrappers', "for client's job", 'Ukrainian automotive sites', 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'have an experience', 'CTO at Periodix.net', 'and/or company data', 'distribute and optimize', 'to crawl js-driven', 'optimize DB queries', '(2 years). Another', 'emails and/or company', 'in a cloud,', 'get companies contact', 'how to simulate', 'I have an', 'site; etc. I', 'sites, including data;', 'crawling Ukrainian automotive', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'duplicates, etc. Thank', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'to get news', 'DB queries and', 'directions from yell.com,', 'jobs crawling to', 'as a CTO', 'based on various', 'pages and terabytes', 'startup (2 years).', 'business directions from', 'databases); yell.com crawling'}
{'simulate browsers and', 'etc. Thank you,', 'to distribute and', 'know how to', 'to simulate browsers', 'js-driven and ajax-driven', 'and ajax-driven sites,', 'how to crawl', 'rid of the', 'and user actions', 'ajax-driven sites, how', 'the load, optimize', 'distribute and optimize', 'browsers and user', 'to crawl js-driven', 'how to distribute', 'optimize the load,', 'load, optimize DB', 'optimize DB queries', 'get rid of', 'how to simulate', 'and avoid bans,', 'bans, how to', 'the duplicates, etc.', 'of the duplicates,', 'avoid bans, how', 'user actions and', 'duplicates, etc. Thank', 'queries and get', 'and get rid', 'crawl js-driven and', 'DB queries and', 'actions and avoid', 'sites, how to', 'I know how', 'and optimize the'}
{'site; making copies', 'and terabytes of', 'to distribute and', 'how to crawl', 'of scanned pages', 'threads in a', 'data. Some of', 'ajax-driven sites, how', 'contact data; auto', 'news crawling to', 'good example is', 'are: groupon and', 'millions of scanned', 'browsers and user', 'including data; news', 'get news flows', 'Some of my', 'of the duplicates,', 'and optimize the', 'Periodix.net startup (2', 'livingsocials crawling (company', 'image processing to', 'Another good example', 'crawling (following search', 'processed data. Some', 'I know how', 'results, getting email', 'terabytes of processed', 'groupon and livingsocials', 'email databases); yell.com', 'data; auto portals', 'during my job', 'copies of some', 'yell.com crawling to', "client's sites; jobs", 'to simulate browsers', 'rid of the', 'to get companies', 'example is crawling', 'get data for', "client's job site;", 'of processed data.', 'is crawling Ukrainian', 'sites during my', 'job as a', 'and avoid bans,', 'active threads in', 'portals crawling and', 'data; news crawling', 'a CTO at', '(company information); google', "client's site; making", "for client's sites;", 'processing to get', 'and livingsocials crawling', 'job site; etc.', 'with 200+ active', 'and image processing', 'crawl js-driven and', 'previous scrappers are:', 'actions and avoid', 'sites, how to', 'crawling to get', 'crawling and image', 'of some sites,', 'google crawling (following', 'know how to', 'js-driven and ajax-driven', 'information); google crawling', 'and ajax-driven sites,', 'companies contact data;', 'a cloud, millions', "flows for client's", 'and user actions', 'sites; jobs crawling', 'how to distribute', 'scrappers are: groupon', 'optimize the load,', 'get rid of', 'cloud, millions of', 'of my other', 'bans, how to', 'the duplicates, etc.', '(following search results,', 'at Periodix.net startup', 'crawling (company information);', '200+ active threads', 'avoid bans, how', 'scanned pages and', "data for client's", 'other previous scrappers', "for client's job", 'simulate browsers and', 'crawling sites during', 'making copies of', 'getting email databases);', 'to get data', 'CTO at Periodix.net', 'distribute and optimize', 'to crawl js-driven', 'in a cloud,', 'get companies contact', 'how to simulate', 'sites, including data;', 'some sites, including', 'user actions and', 'my other previous', 'my job as', 'search results, getting', "for client's site;", 'news flows for', 'auto portals crawling', 'jobs crawling to', 'as a CTO', 'startup (2 years).', 'pages and terabytes', 'to get news', 'databases); yell.com crawling'}
